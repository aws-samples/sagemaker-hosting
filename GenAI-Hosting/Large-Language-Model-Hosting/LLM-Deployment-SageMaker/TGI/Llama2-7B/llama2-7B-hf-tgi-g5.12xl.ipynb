{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Llama 2 (7B) on Amazon SageMaker\n",
    "\n",
    "LLaMA 2 is the next version of the LLaMA. It is trained on more data - 2T tokens and supports context length window upto 4K tokens. Meta fine-tuned conversational models with Reinforcement Learning from Human Feedback on over 1 million human annotations.\n",
    "\n",
    "In this notebook you will learn how to deploy Llama 2 model to Amazon SageMaker. We are going to use the Hugging Face LLM DLC is a new purpose-built Inference Container to easily deploy LLMs in a secure and managed environment. The DLC is powered by [Text Generation Inference (TGI)](https://aws.amazon.com/blogs/machine-learning/announcing-the-launch-of-new-hugging-face-llm-inference-containers-on-amazon-sagemaker/) a scalelable, optimized solution for deploying and serving Large Language Models (LLMs).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup development environment\n",
    "\n",
    "We are going to use the `sagemaker` python SDK to deploy Llama 2 to Amazon SageMaker. We need to make sure to have an AWS account configured and the `sagemaker` python SDK installed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install \"sagemaker>=2.175.0\" --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are going to use Sagemaker in a local environment. You need access to an IAM Role with the required permissions for Sagemaker. You can find [here](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html) more about it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::757967535041:role/sagemamer-access\n",
      "sagemaker session region: us-west-2\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retrieve the new Hugging Face LLM DLC\n",
    "\n",
    "Compared to deploying regular Hugging Face models we first need to retrieve the container uri and provide it to our `HuggingFaceModel` model class with a `image_uri` pointing to the image. To retrieve the new Hugging Face LLM DLC in Amazon SageMaker, we can use the `get_huggingface_llm_image_uri` method provided by the `sagemaker` SDK. This method allows us to retrieve the URI for the desired Hugging Face LLM DLC based on the specified `backend`, `session`, `region`, and `version`. You can find the available versions [here](https://github.com/aws/deep-learning-containers/blob/master/available_images.md#huggingface-text-generation-inference-containers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm image uri: 763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.0.1-tgi0.9.3-gpu-py39-cu118-ubuntu20.04\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "# retrieve the llm image uri\n",
    "llm_image = get_huggingface_llm_image_uri(\n",
    "  \"huggingface\",\n",
    "  version=\"0.9.3\"\n",
    ")\n",
    "\n",
    "# print ecr image uri\n",
    "print(f\"llm image uri: {llm_image}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deploy Llama 2 to Amazon SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# sagemaker config\n",
    "instance_type = \"ml.g5.12xlarge\"\n",
    "number_of_gpu = 4\n",
    "health_check_timeout = 300\n",
    "\n",
    "# Define Model and Endpoint configuration parameter\n",
    "config = {\n",
    "  'HF_MODEL_ID': \"meta-llama/Llama-2-7b-chat-hf\", # model_id from hf.co/models\n",
    "  'SM_NUM_GPUS': json.dumps(number_of_gpu), # Number of GPU used per replica\n",
    "  'MAX_INPUT_LENGTH': json.dumps(2048),  # Max length of input text\n",
    "  'MAX_TOTAL_TOKENS': json.dumps(4096),  # Max length of the generation (including input text)\n",
    "  'MAX_BATCH_TOTAL_TOKENS': json.dumps(8192),  # Limits the number of tokens that can be processed in parallel during the generation\n",
    "  'HUGGING_FACE_HUB_TOKEN': \"<REPLACE WITH YOUR TOKEN>\",\n",
    "}\n",
    "\n",
    "# check if token is set\n",
    "assert config['HUGGING_FACE_HUB_TOKEN'] != \"<REPLACE WITH YOUR TOKEN>\", \"Please set your Hugging Face Hub token\"\n",
    "\n",
    "# create HuggingFaceModel with the image uri\n",
    "llm_model = HuggingFaceModel(\n",
    "  role=role,\n",
    "  image_uri=llm_image,\n",
    "  env=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we have created the `HuggingFaceModel` we can deploy it to Amazon SageMaker using the `deploy` method. We will deploy the model with the `ml.p4d.24xlarge` instance type. TGI will automatically distribute and shard the model across all GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "# Deploy model to an endpoint\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/inference/model.html#sagemaker.model.Model.deploy\n",
    "llm = llm_model.deploy(\n",
    "  initial_instance_count=1,\n",
    "  instance_type=instance_type,\n",
    "  container_startup_health_check_timeout=health_check_timeout, # 10 minutes to be able to load the model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': '\\n\\nWrite a Python program to add two numbers.\\n\\nFor example, if the user enters 5 and 3, the program should output 8.\\n\\nHere is a sample code to get you started:\\n```\\n# Ask the user for two numbers\\nnum1 = int(input(\"Enter the first number: \"))\\nnum2 = int(input(\"Enter the second number: \"))\\n# Add the two numbers\\nresult = num1 + num2\\n'}]\n",
      "[{'generated_text': '\\n\\nWrite a program in Python to add two numbers.\\n\\nHere is an example of how you could do this:\\n```\\n# Add two numbers\\na = 5\\nb = 3\\nresult = a + b\\nprint(\"The result is:\", result)\\n```\\nThis will output \"The result is: 8\".\\n\\nIn this program, the variable `a` is set to the value 5, the variable `b` is set to the'}]\n",
      "[{'generated_text': '\\n\\nWrite a Python program to add two numbers.\\n\\nFor example, if the user enters 5 and 3, the program should print \"7\".\\n\\nHere is a sample solution:\\n```\\n# Ask the user for two numbers\\nnum1 = int(input(\"Enter the first number: \"))\\nnum2 = int(input(\"Enter the second number: \"))\\n# Add the two numbers\\nresult = num1 + num2\\n\\n# Print the'}]\n",
      "[{'generated_text': \"\\n\\nWrite a Python program to add two numbers without using the `+` operator.\\n\\nFor example, if the user enters `5` and `3`, the program should output `8`.\\n\\n**Hint:** You can use the `*` operator to perform multiplication.\\n\\n**Note:** This is a classic interview question, and it's a good idea to test your skills with it. However, keep in mind that it's not the only way to solve\"}]\n",
      "[{'generated_text': '\\n\\nWrite a Python program to add two numbers using the `+` operator.\\n\\nFor example, if you run the following code:\\n```\\na = 5\\nb = 3\\nprint(a + b) # Output: 8\\n```\\nIt will print `8`.\\n\\nNote: You can also use the `+=` operator to add two numbers and assign the result to a variable at the same time. For example:\\n```\\na = '}]\n"
     ]
    }
   ],
   "source": [
    "prompt = \"write a program to add two numbers in python\"\n",
    "for i in range(5):\n",
    "    chat = llm.predict({\"inputs\":prompt,\n",
    "                        \"parameters\": {\n",
    "                                    \"max_new_tokens\": 100,\n",
    "                                    \"do_sample\": True,\n",
    "                                    \"temperature\": 0.4,\n",
    "                                    \"return_full_text\": False\n",
    "                            }\n",
    "                       }\n",
    "                      )\n",
    "\n",
    "    print(chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokens_2k = \"\"\"\n",
    "Summarize the following:\n",
    "\n",
    "Artificial Intelligence (AI) has emerged as a revolutionary force in the field of healthcare, reshaping the entire landscape of this vital industry. Its transformative effects span a wide spectrum, from enhancing medical diagnoses to streamlining administrative tasks, redefining treatment approaches, and even accelerating drug discovery. AI's prowess in medical diagnosis is particularly striking, with machine learning and deep learning algorithms analyzing vast datasets at speeds impossible for humans. These algorithms have exhibited remarkable accuracy in detecting diseases at early stages, such as cancer through image analysis or identifying abnormalities in radiological and pathological scans. The precision and speed at which AI processes medical data have not only improved diagnostic accuracy but also reduced the time required for these critical assessments, potentially saving countless lives.\n",
    "\n",
    "One of AI's most profound impacts in healthcare is the creation of personalized treatment plans tailored to individual patients. By integrating a patient's medical history, genetic data, and lifestyle factors, AI-driven systems can generate treatment recommendations that optimize outcomes and minimize side effects. This approach, often referred to as precision medicine, represents a monumental shift from the one-size-fits-all model of the past, potentially revolutionizing the treatment of various diseases, including cancer, by targeting specific genetic mutations or biomarkers unique to each patient. Patients benefit from more effective treatments, while healthcare providers can make data-driven decisions to ensure better patient outcomes.\n",
    "\n",
    "In addition to clinical applications, AI has made significant inroads in improving the administrative aspects of healthcare. The digitization of medical records, combined with AI's natural language processing capabilities, has streamlined the management of patient information, enabling quick access to critical data and reducing errors associated with manual record-keeping. AI algorithms are also adept at optimizing hospital operations, from scheduling patient appointments to billing and claims processing. These administrative efficiencies not only save time but also reduce costs, contributing to more accessible and affordable healthcare for patients.\n",
    "\n",
    "Furthermore, AI has played a pivotal role in the rise of telemedicine and remote patient monitoring, especially in the context of global health crises such as the COVID-19 pandemic. Telemedicine, driven by AI-driven virtual consultations, has bridged geographical gaps and improved access to medical care, enabling patients to receive timely advice and treatment without the need for physical visits. Remote patient monitoring, facilitated by wearable health technology and AI algorithms, allows for continuous tracking of vital signs and disease progression, enabling early interventions and reducing the burden on healthcare facilities. This combination of telemedicine and remote monitoring has not only transformed healthcare delivery but has also proven crucial in managing public health emergencies.\n",
    "\n",
    "In the realm of drug discovery and development, AI has accelerated traditionally laborious and expensive processes. Machine learning models analyze vast datasets to identify potential drug candidates, speeding up the initial stages of drug discovery. AI is particularly promising in drug repurposing, where existing drugs are reevaluated for new therapeutic uses, potentially bypassing years of research and clinical trials. Additionally, AI aids in clinical trial design by identifying suitable patient cohorts and predicting trial outcomes, thereby enhancing the efficiency and success rate of drug development. This innovation is poised to address the urgent need for novel treatments and therapies in various fields, including oncology and infectious diseases.\n",
    "\n",
    "However, the widespread adoption of AI in healthcare does not come without its ethical considerations. The exponential growth in medical data, often sensitive and personal, raises concerns about data privacy and security. Ensuring that patient information remains confidential and protected from cyber threats becomes a paramount challenge. Moreover, AI algorithms are susceptible to bias, reflecting historical disparities present in healthcare data. Recognizing and mitigating algorithmic bias is essential to prevent the exacerbation of existing healthcare disparities based on race, ethnicity, or socioeconomic status. Striking the right balance between automation and human oversight in medical decision-making also poses ethical questions. While AI can augment clinical decision-making, there is a need to define the scope of AI's authority and ensure that human expertise remains integral in complex medical situations.\n",
    "\n",
    "The integration of AI in healthcare is also reshaping the doctor-patient relationship. Patients now have access to AI-powered health apps and wearable devices, enabling them to monitor their health in real-time and actively engage in their own care. This shift towards patient-centric care empowers individuals to take control of their health and make informed decisions, potentially leading to better health outcomes. However, it also raises questions about the role of healthcare professionals in this new paradigm and the need for effective communication between AI systems, healthcare providers, and patients.\n",
    "\n",
    "Looking forward, the future of healthcare with AI is both promising and complex. AI's potential to improve patient outcomes, increase cost-effectiveness, and revolutionize the healthcare experience is undeniable. However, the field continues to face challenges, including the need for robust regulatory frameworks that ensure patient safety and data privacy. Additionally, addressing the shortage of skilled AI professionals in healthcare and fostering interdisciplinary collaborations between clinicians and data scientists will be crucial for continued progress. As AI continues to evolve and become an integral part of healthcare, the industry must navigate these challenges to unlock its full potential and provide the best possible care to patients.\n",
    "\n",
    "In conclusion, artificial intelligence has ushered in a new era for healthcare, fundamentally transforming how we diagnose, treat, and manage medical conditions. Its applications, from enhancing medical diagnoses and personalized treatment plans to streamlining administrative tasks and drug discovery, hold the promise of improving patient outcomes and making healthcare more accessible and efficient. However, the ethical considerations surrounding data privacy, algorithmic bias, and the evolving doctor-patient relationship necessitate careful navigation. As we venture into the future of healthcare with AI, a balanced approach that combines innovation, regulation, and collaboration will be essential to fully harness its transformative potential.\n",
    "\n",
    "Artificial Intelligence (AI) has emerged as a groundbreaking tool in the field of Magnetic Resonance Imaging (MRI), revolutionizing the way medical professionals acquire, analyze, and interpret images of the human body. This 3000-token exploration delves into the multifaceted impact of AI in MRI, covering its applications in image enhancement, disease detection, image reconstruction, and the challenges and ethical considerations surrounding its adoption.\n",
    "\n",
    "AI in Image Enhancement : AI algorithms have significantly improved image quality in MRI scans. Machine learning models can reduce noise, correct artifacts, and enhance image contrast, providing radiologists with clearer and more detailed images. This enhancement aids in the accurate diagnosis of various medical conditions, from brain tumors to musculoskeletal disorders.\n",
    "\n",
    "Disease Detection and Diagnosis : AI's ability to analyze complex patterns within MRI images has transformed disease detection and diagnosis. Machine learning algorithms can detect subtle abnormalities, such as early-stage cancers, lesions, or neurological disorders, with high accuracy. This early detection can lead to timely interventions and improved patient outcomes.\n",
    "\n",
    "Image Reconstruction: AI-powered image reconstruction techniques have expedited MRI procedures. Through deep learning algorithms, images can be reconstructed from fewer data points or faster acquisition times, reducing patient discomfort and scanner time. This innovation is especially crucial in pediatric and claustrophobic patients.\n",
    "\n",
    "Real-time Image Analysis : AI enables real-time image analysis during MRI scans, allowing radiologists to adjust imaging parameters on the fly for optimal results. This dynamic approach ensures that the highest quality images are obtained, reducing the need for repeated scans and minimizing patient radiation exposure.\n",
    "\n",
    "Quantitative Imaging : AI facilitates quantitative analysis of MRI data, extracting valuable information beyond what the human eye can perceive. It enables the measurement of tissue characteristics, such as volume, density, and perfusion, aiding in disease characterization, treatment planning, and monitoring.\n",
    "\n",
    "Challenges and Considerations : Despite its promise, the integration of AI in MRI is not without challenges. The need for large, high-quality datasets for training AI models, data privacy concerns, and regulatory hurdles pose significant obstacles. Additionally, ensuring the reliability and interpretability of AI-generated results remains a priority to gain the trust of healthcare professionals.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request0:Calling endpoint\n",
      "Request1:Calling endpoint\n",
      "Request2:Calling endpoint\n",
      "Request3:Calling endpoint\n",
      "Request4:Calling endpoint\n",
      "Request5:Calling endpoint\n",
      "Request6:Calling endpoint\n",
      "Request7:Calling endpoint\n",
      "Request8:Calling endpoint\n",
      "Request9:Calling endpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/urllib3/response.py\", line 444, in _error_catcher\n",
      "    yield\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/urllib3/response.py\", line 567, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/urllib3/response.py\", line 533, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/http/client.py\", line 482, in read\n",
      "    s = self._safe_read(self.length)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/http/client.py\", line 633, in _safe_read\n",
      "    raise IncompleteRead(data, amt-len(data))\n",
      "http.client.IncompleteRead: IncompleteRead(0 bytes read, 911 more expected)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/response.py\", line 99, in read\n",
      "    chunk = self._raw_stream.read(amt)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/urllib3/response.py\", line 566, in read\n",
      "    with self._error_catcher():\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/contextlib.py\", line 153, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/urllib3/response.py\", line 461, in _error_catcher\n",
      "    raise ProtocolError(\"Connection broken: %r\" % e, e)\n",
      "urllib3.exceptions.ProtocolError: ('Connection broken: IncompleteRead(0 bytes read, 911 more expected)', IncompleteRead(0 bytes read, 911 more expected))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_13094/748060171.py\", line 8, in invoke_endpoint\n",
      "    chat = llm.predict({\"inputs\": tokens_2k,\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/base_predictor.py\", line 186, in predict\n",
      "    return self._handle_response(response)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/base_predictor.py\", line 192, in _handle_response\n",
      "    return self.deserializer.deserialize(response_body, content_type)\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/base_deserializers.py\", line 265, in deserialize\n",
      "    return json.load(codecs.getreader(\"utf-8\")(stream))\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/json/__init__.py\", line 293, in load\n",
      "    return loads(fp.read(),\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/codecs.py\", line 496, in read\n",
      "    newdata = self.stream.read()\n",
      "  File \"/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/botocore/response.py\", line 104, in read\n",
      "    raise ResponseStreamingError(error=e)\n",
      "botocore.exceptions.ResponseStreamingError: An error occurred while reading from response stream: ('Connection broken: IncompleteRead(0 bytes read, 911 more expected)', IncompleteRead(0 bytes read, 911 more expected))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Ethical Considerations : As AI increasingly influences MRI, ethical considerations arise, such as bias in AI algorithms, transparency in decision-making, and patient autonomy. It is essential to address these concerns to ensure that AI enhances, rather than compromises, patient care and well-being.\\n\\nConclusion : The integration of AI in MRI has revolutionized the field, providing unparalleled image quality, accuracy, and diagnostic capabilities. As AI continues to evolve, it is crucial to address the challenges and ethical considerations surrounding its adoption to ensure that its full potential is realized and patient care is optimized.'}]\n",
      "[{'generated_text': 'Ethical Considerations : The use of AI in MRI raises ethical concerns regarding patient consent, data privacy, and algorithmic bias. As AI models become more sophisticated, there is a risk of perpetuating existing health disparities, particularly if the training data are not diverse enough. It is essential to address these concerns through transparent AI development, diversified data sets, and inclusive clinical decision-making.\\n\\nIn conclusion, the integration of AI in MRI has revolutionized the field, offering improved image quality, enhanced disease detection, and expedited image reconstruction. However, addressing the challenges and ethical considerations surrounding its adoption is crucial to ensure that AI-driven MRI delivers optimal patient outcomes and maintains the trust of healthcare professionals and patients alike.'}]\n",
      "[{'generated_text': 'Ethical Implications : The use of AI in MRI raises ethical considerations, such as the potential for bias in algorithms, the need for transparency in decision-making, and the impact on the patient-radiologist relationship. It is essential to address these concerns through open dialogue and collaboration among healthcare professionals, policymakers, and the public.\\n\\nConclusion : Artificial Intelligence has revolutionized the field of Magnetic Resonance Imaging, transforming the way medical professionals acquire, analyze, and interpret images of the human body. AI has improved image quality, enhanced disease detection, and expedited image reconstruction. However, challenges and ethical considerations must be addressed to ensure the safe and effective integration of AI in MRI. By fostering collaboration and open dialogue, we can harness the full potential of AI in MRI to improve patient outcomes and enhance the quality of healthcare.'}]\n",
      "[{'generated_text': 'Ethical Considerations : As AI becomes more prevalent in MRI, ethical considerations arise regarding data ownership, bias in algorithms, and the potential for AI to replace human radiologists. It is essential to address these concerns through transparent data sharing, diverse algorithm development, and ongoing collaboration between AI developers, radiologists, and patients.\\n\\nConclusion : The integration of AI in MRI has transformed the field, enhancing image quality, detecting diseases, and streamlining image reconstruction. However, challenges and ethical considerations must be addressed to ensure the responsible and effective use of AI in medical imaging. By prioritizing data quality, algorithmic transparency, and patient safety, we can unlock the full potential of AI in MRI and improve patient outcomes.'}]\n",
      "[{'generated_text': 'Ethical Considerations : The use of AI in MRI raises ethical concerns, such as bias in image interpretation and the potential for AI to replace human radiologists. It is essential to address these concerns through transparent AI development and deployment, ensuring that AI complements rather than replaces human expertise.\\n\\nConclusion : The integration of AI in MRI has revolutionized the field, improving image quality, disease detection, and diagnostic accuracy. However, addressing the challenges and ethical considerations surrounding AI adoption is crucial to ensure its safe and effective use in clinical practice. By fostering collaboration between AI developers, radiologists, and regulatory bodies, we can harness the full potential of AI in MRI, leading to better patient outcomes and improved healthcare.'}]\n",
      "[{'generated_text': 'Ethical Considerations : The use of AI in MRI raises ethical concerns, such as bias in algorithms, patient privacy, and the potential for AI to replace human radiologists. Addressing these issues is crucial to ensure that AI is used responsibly and ethically in the medical field.\\n\\nConclusion : Artificial Intelligence has revolutionized the field of Magnetic Resonance Imaging, offering improved image quality, enhanced disease detection, and faster image reconstruction. While challenges and ethical considerations must be addressed, the integration of AI in MRI has the potential to transform patient care and outcomes. As the technology continues to evolve, it is essential to prioritize responsible and ethical AI adoption in the medical field.'}]\n",
      "[{'generated_text': 'Ethical Considerations : As AI becomes more prevalent in MRI, ethical considerations arise. The potential for bias in AI algorithms, the need for transparency in decision-making, and the impact of AI on the patient-clinician relationship must be addressed. Ensuring that AI complements human expertise rather than replacing it is crucial for maintaining the highest standards of patient care.\\n\\nConclusion : The integration of AI in MRI has revolutionized the field, offering new possibilities for image enhancement, disease detection, image reconstruction, and real-time analysis. While challenges and ethical considerations must be addressed, the potential benefits of AI in MRI are undeniable. As the technology continues to evolve, it is essential to prioritize collaboration between AI developers, healthcare professionals, and policymakers to ensure that AI is used responsibly and effectively in medical imaging.'}]\n",
      "[{'generated_text': 'Ethical Considerations : As AI becomes more prevalent in MRI, ethical questions arise regarding patient consent, data ownership, and algorithmic biases. It is crucial to address these concerns through transparent communication, robust data protection measures, and diverse, inclusive AI development teams.\\n\\nConclusion : AI has revolutionized MRI, transforming the field and improving patient outcomes. Its applications in image enhancement, disease detection, image reconstruction, and real-time analysis have the potential to revolutionize medical imaging. However, addressing the challenges and ethical considerations surrounding AI integration is essential to ensure its safe, effective, and equitable use in clinical practice.'}]\n",
      "[{'generated_text': 'Ethical Considerations : The use of AI in MRI raises ethical concerns, such as the potential for bias in AI algorithms, the impact on radiologist jobs, and the need for transparency in AI-driven decision-making. Addressing these issues is crucial to ensure that AI enhances patient care without compromising ethical standards.\\n\\n\\nConclusion : The integration of AI in MRI has revolutionized the field, improving image quality, enhancing disease detection, and accelerating image reconstruction. While challenges and ethical considerations must be addressed, the potential benefits of AI in MRI are undeniable. As the technology continues to evolve, it is essential to prioritize collaboration between AI developers, radiologists, and policymakers to ensure that AI is used responsibly and ethically to improve patient care.'}]\n",
      "Latency (p90):  18.258483552932738\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Manager\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def invoke_endpoint(name, L):\n",
    "    start_time = time.time()\n",
    "    print(f\"{name}:Calling endpoint\")\n",
    "    chat = llm.predict({\"inputs\": tokens_2k,\n",
    "                        \"parameters\": {\n",
    "                                    \"max_new_tokens\": 500,\n",
    "                                    \"min_new_tokens\": 500,\n",
    "                                    \"do_sample\": True,\n",
    "                                    \"temperature\": 0.4,\n",
    "                                    \"return_full_text\": False\n",
    "                            }\n",
    "                       }\n",
    "                      )\n",
    "    end_time = time.time()\n",
    "    L.append(end_time-start_time)\n",
    "    print(chat)\n",
    "\n",
    "all_processes = []\n",
    "with Manager() as manager:\n",
    "    L = manager.list()\n",
    "    for i in range(10):\n",
    "        p = Process(target=invoke_endpoint, args=('Request'+str(i), L))\n",
    "        p.start()\n",
    "        all_processes.append(p)\n",
    "\n",
    "    for p in all_processes:\n",
    "        p.join()\n",
    "        \n",
    "    print(\"Latency (p90): \", np.percentile(L, 90))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run inference and chat with the model\n",
    "\n",
    "After our endpoint is deployed we can run inference on it. We will use the `predict` method from the `predictor` to run inference on our endpoint. We can inference with different parameters to impact the generation. Parameters can be defined as in the `parameters` attribute of the payload. As of today the TGI supports the following parameters:\n",
    "* `temperature`: Controls randomness in the model. Lower values will make the model more deterministic and higher values will make the model more random. Default value is 1.0.\n",
    "* `max_new_tokens`: The maximum number of tokens to generate. Default value is 20, max value is 512.\n",
    "* `repetition_penalty`: Controls the likelihood of repetition, defaults to `null`.\n",
    "* `seed`: The seed to use for random generation, default is `null`.\n",
    "* `stop`: A list of tokens to stop the generation. The generation will stop when one of the tokens is generated.\n",
    "* `top_k`: The number of highest probability vocabulary tokens to keep for top-k-filtering. Default value is `null`, which disables top-k-filtering.\n",
    "* `top_p`: The cumulative probability of parameter highest probability vocabulary tokens to keep for nucleus sampling, default to `null`\n",
    "* `do_sample`: Whether or not to use sampling ; use greedy decoding otherwise. Default value is `false`.\n",
    "* `best_of`: Generate best_of sequences and return the one if the highest token logprobs, default to `null`.\n",
    "* `details`: Whether or not to return details about the generation. Default value is `false`.\n",
    "* `return_full_text`: Whether or not to return the full text or only the generated part. Default value is `false`.\n",
    "* `truncate`: Whether or not to truncate the input to the maximum length of the model. Default value is `true`.\n",
    "* `typical_p`: The typical probability of a token. Default value is `null`.\n",
    "* `watermark`: The watermark to use for the generation. Default value is `false`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Clean up\n",
    "\n",
    "To clean up, we can delete the model and endpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# llm.delete_model()\n",
    "# llm.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "5fcf248a74081676ead7e77f54b2c239ba2921b952f7cbcdbbe5427323165924"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
