{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df0d57a8",
   "metadata": {},
   "source": [
    "# Pytorch ModelBuilder\n",
    "\n",
    "This notebook was tested with the `conda_pytorch_p310` kernel on an Amazon SageMaker notebook instance of type `m5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27e9a7f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install boto3 sagemaker -U -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2251f8-175b-4b81-ad47-1c48f3a0178d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install torch==2.0.1 torchvision==0.15.2 transformers==4.31.0 -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0974aacb",
   "metadata": {},
   "source": [
    "# SageMaker ModelBuilder experience"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b91159",
   "metadata": {},
   "source": [
    "In the new experience, we have introduced a few new constructs. Here we will focus on the following: \n",
    "\n",
    "1. ModelBuilder\n",
    "2. SchemaBuilder\n",
    "3. InferenceSpec\n",
    "\n",
    "In the following section, we will define these constructs and provide examples to elaborate on each one.\n",
    "\n",
    "4.1 ModelBuilder:\n",
    "\n",
    "ModelBuilder is a Python class that takes a framework model (such as XGBoost or PyTorch) or an Inference Spec (more details below) and converts them into a SageMaker deployable model. ModelBuilder provides a `build` function that generates the artifacts for deployment. The model artifact generated is specific to the model server, which is also customizable as one of the inputs.\n",
    "\n",
    "```python\n",
    "Class definition:\n",
    "\n",
    "class ModelBuilder(\n",
    "    model_path: str | None = '/tmp/sagemaker/model-builder/' + uuid.uuid1().hex,\n",
    "    role_arn: str | None = None,\n",
    "    sagemaker_session: Session | None = None,\n",
    "    name: str | None = 'model-name-' + uuid.uuid1().hex,\n",
    "    mode: Mode | None = Mode.SAGEMAKER_ENDPOINT,\n",
    "    shared_libs: List[str] = lambda : [],\n",
    "    dependencies: Dict[str, Any] | None = lambda : { \"auto\": False },\n",
    "    env_vars: Dict[str, str] | None = lambda : {},\n",
    "    log_level: int | None = logging.DEBUG,\n",
    "    content_type: str | None = None,\n",
    "    accept_type: str | None = None,\n",
    "    s3_model_data_url: str | None = None,\n",
    "    instance_type: str | None = \"ml.c5.xlarge\",\n",
    "    schema_builder: str | None = None,\n",
    "    model: Any | None = None,\n",
    "    inference_spec: InferenceSpec = None,\n",
    "    image_uri: str | None = None,\n",
    "    model_server: str | None = None\n",
    ")\n",
    "```\n",
    "Example:\n",
    "\n",
    "The above class file provide all the options for customization. However to deploy the framework model, the model builder just expects model, input, output and the role. \n",
    "\n",
    "```python\n",
    "model_builder = ModelBuilder(\n",
    "    model=model,  # Pass in the actual model object. It's \"predict\" method will be invoked in the endpoint.\n",
    "    schema_builder=SchemaBuilder(input, output), # Pass in a \"SchemaBuilder\" which will use the sample test input and output objects to infer the serialization needed.\n",
    "    role_arn=role, # Pass in the role arn or update intelligent defaults.\n",
    "    )\n",
    "```\n",
    "\n",
    "4.2 SchemaBuilder:\n",
    "\n",
    "The SchemaBuilder enables you to define the input and output for your endpoint. It allows the SchemaBuilder to generate the corresponding marshalling functions for serializing and deserializing the input and output. For further details, please consult the notebook or refer to the video.\n",
    "\n",
    "Class definition:\n",
    "```python\n",
    "class SchemaBuilder(\n",
    "    sample_input: Any,\n",
    "    sample_output: Any,\n",
    "    input_translator: CustomPayloadTranslator = None,\n",
    "    output_translator: CustomPayloadTranslator = None\n",
    ")\n",
    "```\n",
    "Example:\n",
    "\n",
    "The CustomPayloadTranslator class provides all the options for customization. However, for [common inference data format](https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-inference.html), you can just provide the sample input/output for the SchemaBuilder.\n",
    "```python\n",
    "input = \"How is the demo going?\"\n",
    "output = \"Comment la d√©mo va-t-elle?\"\n",
    "schema = SchemaBuilder(input, output)\n",
    "```\n",
    "\n",
    "4.3 InferenceSpec\n",
    "\n",
    "In the case you want to specify custom function to load and invoke the model instead of the framework model function, then you can pass the inference spec with your implementation in `load` and `invoke` function. \n",
    "\n",
    "class definition:\n",
    "```python\n",
    "class InferenceSpec(abc.ABC):\n",
    "    @abc.abstractmethod\n",
    "    def load(self, model_dir: str):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def invoke(self, input_object: object, model: object):\n",
    "        pass\n",
    "```\n",
    "Example:\n",
    "```python\n",
    "class MyInferenceSpec(InferenceSpec):\n",
    "    def load(self, model_dir: str):\n",
    "        return pipeline(\"translation_en_to_fr\", model=\"t5-small\")\n",
    "        \n",
    "    def invoke(self, input, model):\n",
    "        return model(input)\n",
    "   \n",
    "inf_spec = MyInferenceSpec()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6481b830-e1ae-459e-8549-32384c4bbe80",
   "metadata": {},
   "source": [
    "In this example, we are using ModelBuilder to deploy a pretrained model from Hugging Face directly. You can use `Mode` to switch between local testing and deploying to a SageMaker Endpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3351efc2-cc4e-4a6e-ad0c-bf2c6ab87953",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role, Session, image_uris\n",
    "import boto3\n",
    "sagemaker_session = Session()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# get execution role\n",
    "# please use execution role if you are using notebook instance or update the role arn if you are using a different role\n",
    "execution_role = get_execution_role() if get_execution_role() is not None else \"your-role-arn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4976f97b-f576-4269-b013-741cefd01262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris\n",
    "instance_type = 'ml.g5.2xlarge'\n",
    "image = image_uris.retrieve(region=region, framework='huggingface', image_scope='inference', version='4.28.1', base_framework_version='pytorch2.0.0', instance_type=instance_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e23e5d-c863-4528-a3b8-ec83cd6889e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serve.spec.inference_spec import InferenceSpec\n",
    "from transformers import pipeline\n",
    "\n",
    "# custom inference spec with hugging face pipeline\n",
    "class MyInferenceSpec(InferenceSpec):\n",
    "    def load(self, model_dir: str):\n",
    "        return pipeline(\"translation_en_to_fr\", model=\"t5-small\")\n",
    "        \n",
    "    def invoke(self, input, model):\n",
    "        return model(input)\n",
    "    \n",
    "    \n",
    "inf_spec = MyInferenceSpec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58184f43-61b4-4299-b873-bc2cf6ff5fbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serve.builder.model_builder import ModelBuilder\n",
    "from sagemaker.serve import ModelServer\n",
    "from sagemaker.serve import Mode\n",
    "from sagemaker.serve.builder.schema_builder import SchemaBuilder\n",
    "\n",
    "value: str = \"Girafatron is obsessed with giraffes, the most glorious animal on the face of this Earth. Giraftron believes all other animals are irrelevant when compared to the glorious majesty of the giraffe.\\nDaniel: Hello, Girafatron!\\nGirafatron:\"\n",
    "schema = SchemaBuilder(value,\n",
    "            {\"generated_text\": \"Girafatron is obsessed with giraffes, the most glorious animal on the face of this Earth. Giraftron believes all other animals are irrelevant when compared to the glorious majesty of the giraffe.\\\\nDaniel: Hello, Girafatron!\\\\nGirafatron: Hi, Daniel. I was just thinking about how magnificent giraffes are and how they should be worshiped by all.\\\\nDaniel: You and I think alike, Girafatron. I think all animals should be worshipped! But I guess that could be a bit impractical...\\\\nGirafatron: That\\'s true. But the giraffe is just such an amazing creature and should always be respected!\\\\nDaniel: Yes! And the way you go on about giraffes, I could tell you really love them.\\\\nGirafatron: I\\'m obsessed with them, and I\\'m glad to hear you noticed!\\\\nDaniel: I\\'\"})\n",
    "\n",
    "# deploying the model to a SageMaker Endpoint\n",
    "builder = ModelBuilder(inference_spec=inf_spec, \n",
    "                       mode=Mode.SAGEMAKER_ENDPOINT,  # you can change it to Mode.LOCAL_CONTAINER for local testing\n",
    "                       schema_builder=schema,\n",
    "                       image_uri=image,\n",
    "                       model_server=ModelServer.TORCHSERVE\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d569f5d8-0185-496a-bd8f-1a5835db8da2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import serve, Session\n",
    "import boto3\n",
    "\n",
    "# build the model according the model server specification and save it to as files in the working directory\n",
    "model = builder.build(\n",
    "    role_arn=execution_role,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ef5548-2178-48c4-83e5-6e808be1ce30",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# deploying the model on a SageMaker Endpoint, this process may take around 6~10 mins\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cb9101-9c26-44ba-8c9f-b2a3b640733f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# predict call on local container mode\n",
    "predictor.predict(\"How is the demo going?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd8f0fe",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68053e21-a69d-4b1d-8a64-7d3f13e53cc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807561be-8a3f-4969-ae52-fc795d049530",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
