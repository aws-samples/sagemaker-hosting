{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df0d57a8",
   "metadata": {},
   "source": [
    "# Pytorch ModelBuilder\n",
    "\n",
    "This notebook was tested with the `conda_pytorch_p310` kernel on an Amazon SageMaker notebook instance of type `m5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27e9a7f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install boto3 sagemaker -U -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2251f8-175b-4b81-ad47-1c48f3a0178d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install torch==2.0.1 torchvision==0.15.2 transformers==4.31.0 -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0974aacb",
   "metadata": {},
   "source": [
    "# SageMaker ModelBuilder experience"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b91159",
   "metadata": {},
   "source": [
    "In the new experience, we have introduced a few new constructs. Here we will focus on the following: \n",
    "\n",
    "1. ModelBuilder\n",
    "2. SchemaBuilder\n",
    "3. InferenceSpec\n",
    "\n",
    "In the following section, we will define these constructs and provide examples to elaborate on each one.\n",
    "\n",
    "4.1 ModelBuilder:\n",
    "\n",
    "ModelBuilder is a Python class that takes a framework model (such as XGBoost or PyTorch) or an Inference Spec (more details below) and converts them into a SageMaker deployable model. ModelBuilder provides a `build` function that generates the artifacts for deployment. The model artifact generated is specific to the model server, which is also customizable as one of the inputs.\n",
    "\n",
    "```python\n",
    "Class definition:\n",
    "\n",
    "class ModelBuilder(\n",
    "    model_path: str | None = '/tmp/sagemaker/model-builder/' + uuid.uuid1().hex,\n",
    "    role_arn: str | None = None,\n",
    "    sagemaker_session: Session | None = None,\n",
    "    name: str | None = 'model-name-' + uuid.uuid1().hex,\n",
    "    mode: Mode | None = Mode.SAGEMAKER_ENDPOINT,\n",
    "    shared_libs: List[str] = lambda : [],\n",
    "    dependencies: Dict[str, Any] | None = lambda : { \"auto\": False },\n",
    "    env_vars: Dict[str, str] | None = lambda : {},\n",
    "    log_level: int | None = logging.DEBUG,\n",
    "    content_type: str | None = None,\n",
    "    accept_type: str | None = None,\n",
    "    s3_model_data_url: str | None = None,\n",
    "    instance_type: str | None = \"ml.c5.xlarge\",\n",
    "    schema_builder: str | None = None,\n",
    "    model: Any | None = None,\n",
    "    inference_spec: InferenceSpec = None,\n",
    "    image_uri: str | None = None,\n",
    "    model_server: str | None = None\n",
    ")\n",
    "```\n",
    "Example:\n",
    "\n",
    "The above class file provide all the options for customization. However to deploy the framework model, the model builder just expects model, input, output and the role. \n",
    "\n",
    "```python\n",
    "model_builder = ModelBuilder(\n",
    "    model=model,  # Pass in the actual model object. It's \"predict\" method will be invoked in the endpoint.\n",
    "    schema_builder=SchemaBuilder(input, output), # Pass in a \"SchemaBuilder\" which will use the sample test input and output objects to infer the serialization needed.\n",
    "    role_arn=role, # Pass in the role arn or update intelligent defaults.\n",
    "    )\n",
    "```\n",
    "\n",
    "4.2 SchemaBuilder:\n",
    "\n",
    "The SchemaBuilder enables you to define the input and output for your endpoint. It allows the SchemaBuilder to generate the corresponding marshalling functions for serializing and deserializing the input and output. For further details, please consult the notebook or refer to the video.\n",
    "\n",
    "Class definition:\n",
    "```python\n",
    "class SchemaBuilder(\n",
    "    sample_input: Any,\n",
    "    sample_output: Any,\n",
    "    input_translator: CustomPayloadTranslator = None,\n",
    "    output_translator: CustomPayloadTranslator = None\n",
    ")\n",
    "```\n",
    "Example:\n",
    "\n",
    "The CustomPayloadTranslator class provides all the options for customization. However, for [common inference data format](https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-inference.html), you can just provide the sample input/output for the SchemaBuilder.\n",
    "```python\n",
    "input = \"How is the demo going?\"\n",
    "output = \"Comment la d√©mo va-t-elle?\"\n",
    "schema = SchemaBuilder(input, output)\n",
    "```\n",
    "\n",
    "4.3 InferenceSpec\n",
    "\n",
    "In the case you want to specify custom function to load and invoke the model instead of the framework model function, then you can pass the inference spec with your implementation in `load` and `invoke` function. \n",
    "\n",
    "class definition:\n",
    "```python\n",
    "class InferenceSpec(abc.ABC):\n",
    "    @abc.abstractmethod\n",
    "    def load(self, model_dir: str):\n",
    "        pass\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def invoke(self, input_object: object, model: object):\n",
    "        pass\n",
    "```\n",
    "Example:\n",
    "```python\n",
    "class MyInferenceSpec(InferenceSpec):\n",
    "    def load(self, model_dir: str):\n",
    "        return pipeline(\"translation_en_to_fr\", model=\"t5-small\")\n",
    "        \n",
    "    def invoke(self, input, model):\n",
    "        return model(input)\n",
    "   \n",
    "inf_spec = MyInferenceSpec()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6481b830-e1ae-459e-8549-32384c4bbe80",
   "metadata": {},
   "source": [
    "In this example, we are using ModelBuilder to deploy an PyTorch model directly. You can use `Mode` to switch between local testing and deploying to a SageMaker Endpoint. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439408e5-2534-4bce-9437-62fc01194ca0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### PyTorch model deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3351efc2-cc4e-4a6e-ad0c-bf2c6ab87953",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role, Session, image_uris\n",
    "import boto3\n",
    "\n",
    "sagemaker_session = Session()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# get execution role\n",
    "# please use execution role if you are using notebook instance or update the role arn if you are using a different role\n",
    "execution_role = get_execution_role() if get_execution_role() is not None else \"your-role-arn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58184f43-61b4-4299-b873-bc2cf6ff5fbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clean up any working directories\n",
    "!sudo rm -r \"./working_dir/models/resnet_v2_demo/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d569f5d8-0185-496a-bd8f-1a5835db8da2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get the local working of resnet model\n",
    "import torch\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "resnet_model_dir = \"./working_dir/models/resnet_v2_demo\"\n",
    "!mkdir -p {resnet_model_dir}\n",
    "\n",
    "resnet_model_path = Path(resnet_model_dir+ '/model.pth')\n",
    "resnet_model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "torch.save(resnet_model.state_dict(), resnet_model_path)\n",
    "image_path = Path('./pytorch/zidane.jpeg').resolve()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ef5548-2178-48c4-83e5-6e808be1ce30",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load model from local disk\n",
    "resnet_model = resnet50()\n",
    "resnet_model.load_state_dict(torch.load(str(resnet_model_path)))\n",
    "\n",
    "# Define image transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load image\n",
    "image = Image.open(str(image_path))\n",
    "image_tensor = transform(image)\n",
    "input_batch = image_tensor.unsqueeze(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = resnet_model(input_batch)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95bf805-0a53-4ba1-a34b-04b2a02eeb12",
   "metadata": {},
   "source": [
    "#### Deploy model using ModelBuilder\n",
    "\n",
    "Now we will deploy the model using ModelBuilder.\n",
    "\n",
    "By default, when you pass the samples, ModelBuilder will be able to generate marshaling function. However in case you want to do it because of the custom nature, then you need to build translator. The process will be like below:\n",
    "\n",
    "* (1) Inference request serialization (handled by the client)\n",
    "* (2) Inference request deserialization (handled by the server or algorithm)\n",
    "* (3) (4) Invoke the model against the payload and send response payload back\n",
    "* (5) Inference response serialization (handled by the server or algorithm)\n",
    "* (6) Inference response deserialization (handled by the client)\n",
    "\n",
    "![diagram](./img/serialization-deserialization.png)\n",
    "\n",
    "Note that all to_function are taken care by translator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4053938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serve import CustomPayloadTranslator\n",
    "\n",
    "# request translator\n",
    "class MyRequestTranslator(CustomPayloadTranslator):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Define image transformation\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "    \n",
    "    # This function converts the payload to bytes - happens on client side\n",
    "    def serialize_payload_to_bytes(self, payload: object) -> bytes:\n",
    "        # converts an image to bytes\n",
    "        image_tensor = self.transform(payload)\n",
    "        input_batch = image_tensor.unsqueeze(0)\n",
    "        input_ndarray = input_batch.numpy()\n",
    "        return self._convert_numpy_to_bytes(input_ndarray)\n",
    "        \n",
    "    # This function converts the bytes to payload - happens on server side\n",
    "    def deserialize_payload_from_stream(self, stream) -> torch.Tensor:\n",
    "        # convert payload back to torch.Tensor\n",
    "        np_array = np.load(io.BytesIO(stream.read()))\n",
    "        return torch.from_numpy(np_array)\n",
    "        \n",
    "    def _convert_numpy_to_bytes(self, np_array: np.ndarray) -> bytes:\n",
    "        buffer = io.BytesIO()\n",
    "        np.save(buffer, np_array)\n",
    "        return buffer.getvalue()\n",
    "    \n",
    "# response translator \n",
    "class MyResponseTranslator(CustomPayloadTranslator):\n",
    "    # This function converts the payload to bytes - happens on server side\n",
    "    def serialize_payload_to_bytes(self, payload: torch.Tensor) -> bytes:\n",
    "        return self._convert_numpy_to_bytes(payload.numpy())\n",
    "    \n",
    "    # This function converts the bytes to payload - happens on client side\n",
    "    def deserialize_payload_from_stream(self, stream) -> object:\n",
    "        return torch.from_numpy(np.load(io.BytesIO(stream.read())))\n",
    "    \n",
    "    def _convert_numpy_to_bytes(self, np_array: np.ndarray) -> bytes:\n",
    "        buffer = io.BytesIO()\n",
    "        np.save(buffer, np_array)\n",
    "        return buffer.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbc79aa-99c6-4fe0-80e3-06441e01e4ea",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serve import SchemaBuilder\n",
    "\n",
    "# pass in the sample input and output, along with above translators\n",
    "my_schema = SchemaBuilder(\n",
    "    sample_input=image, \n",
    "    sample_output=output,\n",
    "    input_translator=MyRequestTranslator(), \n",
    "    output_translator=MyResponseTranslator()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24f980e-d0b9-4310-bb98-f715fd77112d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.serve import InferenceSpec\n",
    "\n",
    "# custom inference spec\n",
    "class MyResNetModel(InferenceSpec):\n",
    "    def invoke(self, input_object: object, model: object):       \n",
    "        with torch.no_grad():\n",
    "            output = model(input_object)\n",
    "        return output\n",
    "        \n",
    "    def load(self, model_dir: str):\n",
    "        model = resnet50()\n",
    "        model.load_state_dict(torch.load(model_dir+'/model.pth'))\n",
    "        model.eval()\n",
    "        return model\n",
    "\n",
    "my_inference_spec = MyResNetModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a076762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serve import ModelBuilder\n",
    "from sagemaker.serve.mode.function_pointers import Mode\n",
    "from sagemaker.session import Session\n",
    "import boto3\n",
    "\n",
    "# python absolute path from relative path for local deployment to work. -- we will fix this\n",
    "resnet_model_dir = str(Path(resnet_model_dir).resolve())\n",
    "\n",
    "# Create model builder with above custom inference spec and schema builder\n",
    "model_builder = ModelBuilder(\n",
    "    mode=Mode.SAGEMAKER_ENDPOINT,  # you can change it to Mode.LOCAL_CONTAINER for local testing\n",
    "    model_path=resnet_model_dir,\n",
    "    inference_spec=my_inference_spec,\n",
    "    schema_builder=my_schema,\n",
    "    role_arn=execution_role,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec85cee5-c7a0-4f0c-ae1c-71775d0cf2b1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build the model according to the model server specification and save it to as files in the working directory\n",
    "model = model_builder.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf575a1-7d6d-43fd-a1b2-733e976a1721",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# deploy is an existing method in the model object, however we have enabled live loggging for easier debugging.\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.c6i.xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4931f2e3-5c11-41e3-b526-fab2d090ee44",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load image and preprocess\n",
    "image = Image.open(str(image_path))\n",
    "\n",
    "# make inference call\n",
    "predictor.predict(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd8f0fe",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68053e21-a69d-4b1d-8a64-7d3f13e53cc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807561be-8a3f-4969-ae52-fc795d049530",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
